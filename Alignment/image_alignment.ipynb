{
 "cells": [
  {
   "cell_type": "code",
   "id": "8179610b-6c82-4932-ba9c-60d85a91b2ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T13:55:55.404976Z",
     "start_time": "2024-06-17T13:55:54.954236Z"
    }
   },
   "source": [
    "from __future__ import print_function\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "3f0b71d5-0721-454a-8d29-78049ba16222",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T13:55:55.411813Z",
     "start_time": "2024-06-17T13:55:55.406408Z"
    }
   },
   "source": [
    "def alignImages_ORB(im1, im2):\n",
    "    im1Gray = cv2.cvtColor(im1, cv2.COLOR_BGR2GRAY)\n",
    "    im2Gray = cv2.cvtColor(im2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    orb = cv2.ORB_create(MAX_MATCHES)\n",
    "    keypoints1, descriptors1 = orb.detectAndCompute(im1Gray, None)\n",
    "    keypoints2, descriptors2 = orb.detectAndCompute(im2Gray, None)\n",
    "\n",
    "    # Match features.\n",
    "    matcher = cv2.DescriptorMatcher_create(cv2.DESCRIPTOR_MATCHER_BRUTEFORCE_HAMMING)\n",
    "    matches = list(matcher.match(descriptors1, descriptors2, None))\n",
    "\n",
    "    # Sort matches by score\n",
    "    matches.sort(key=lambda x: x.distance, reverse=False)\n",
    "\n",
    "    # Remove not so good matches\n",
    "    numGoodMatches = int(len(matches) * GOOD_MATCH_PERCENT)\n",
    "    matches = matches[:numGoodMatches]\n",
    "    print(len(matches))\n",
    "\n",
    "    # Draw top matches\n",
    "    imMatches = cv2.drawMatches(im1, keypoints1, im2, keypoints2, matches, None)\n",
    "    \n",
    "    # Extract location of good matches\n",
    "    points1 = np.zeros((len(matches), 2), dtype=np.float32)\n",
    "    points2 = np.zeros((len(matches), 2), dtype=np.float32)\n",
    "\n",
    "    for i, match in enumerate(matches):\n",
    "        points1[i, :] = keypoints1[match.queryIdx].pt\n",
    "        points2[i, :] = keypoints2[match.trainIdx].pt\n",
    "\n",
    "    # Find homography\n",
    "    h, mask = cv2.findHomography(points1, points2, cv2.RANSAC)\n",
    "\n",
    "    # Use homography\n",
    "    height, width, channels = im2.shape\n",
    "    im1Reg = cv2.warpPerspective(im1, h, (width, height))\n",
    "\n",
    "    return imMatches, im1Reg, h"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T13:55:55.419256Z",
     "start_time": "2024-06-17T13:55:55.412817Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def alignImages_SIFT(im1, im2):\n",
    "    im1Gray = cv2.cvtColor(im1, cv2.COLOR_BGR2GRAY)\n",
    "    im2Gray = cv2.cvtColor(im2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    orb = cv2.SIFT_create(MAX_MATCHES)\n",
    "    keypoints1, descriptors1 = orb.detectAndCompute(im1Gray, None)\n",
    "    keypoints2, descriptors2 = orb.detectAndCompute(im2Gray, None)\n",
    "\n",
    "    # Match features.\n",
    "    matcher = cv2.BFMatcher()\n",
    "    matches = matcher.match(descriptors1, descriptors2, k=2)\n",
    "\n",
    "    good = []\n",
    "    for m,n in matches:\n",
    "        if m.distance < 0.75*n.distance:\n",
    "            good.append([m])\n",
    "\n",
    "    # Draw top matches\n",
    "    imMatches = cv2.drawMatchesKnn(im1, keypoints1, im2, keypoints2, matches, None)\n",
    "\n",
    "    # Extract location of good matches\n",
    "    points1 = np.zeros((len(matches), 2), dtype=np.float32)\n",
    "    points2 = np.zeros((len(matches), 2), dtype=np.float32)\n",
    "\n",
    "    for i, match in enumerate(matches):\n",
    "        points1[i, :] = keypoints1[match.queryIdx].pt\n",
    "        points2[i, :] = keypoints2[match.trainIdx].pt\n",
    "\n",
    "    # Find homography\n",
    "    h, mask = cv2.findHomography(points1, points2, cv2.RANSAC)\n",
    "\n",
    "    # Use homography\n",
    "    height, width, channels = im2.shape\n",
    "    im1Reg = cv2.warpPerspective(im1, h, (width, height))\n",
    "\n",
    "    return imMatches, im1Reg, h"
   ],
   "id": "896abefd489cc7da",
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "dc444a87-ed85-496b-aa7a-bbb499d2cb0f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T13:55:55.423257Z",
     "start_time": "2024-06-17T13:55:55.420265Z"
    }
   },
   "source": [
    "MAX_MATCHES = 10000\n",
    "GOOD_MATCH_PERCENT = 0.001"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "2c519735-8e7f-4886-898e-3600db39c7c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T13:55:56.236935Z",
     "start_time": "2024-06-17T13:55:55.424261Z"
    }
   },
   "source": [
    "refFilename = \"ace_heart.png\"\n",
    "imReference = cv2.imread(refFilename, cv2.IMREAD_COLOR)\n",
    "# imReference = cv2.resize(imReference,(0,0),fx=0.5,fy=0.5)\n",
    "\n",
    "imFilename = \"bai.jpg\"\n",
    "im = cv2.imread(imFilename, cv2.IMREAD_COLOR)\n",
    "im = cv2.resize(im,(0,0),fx=0.5,fy=0.5)\n",
    "\n",
    "imMatches, imReg, h = alignImages_SIFT(im, imReference)\n",
    "# Print estimated homography\n",
    "print(\"Estimated homography : \\n\", h)\n"
   ],
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.9.0) :-1: error: (-5:Bad argument) in function 'match'\n> Overload resolution failed:\n>  - 'k' is an invalid keyword argument for DescriptorMatcher.match()\n>  - 'k' is an invalid keyword argument for DescriptorMatcher.match()\n>  - DescriptorMatcher.match() takes at most 2 arguments (3 given)\n>  - DescriptorMatcher.match() takes at most 2 arguments (3 given)\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31merror\u001B[0m                                     Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[5], line 9\u001B[0m\n\u001B[0;32m      6\u001B[0m im \u001B[38;5;241m=\u001B[39m cv2\u001B[38;5;241m.\u001B[39mimread(imFilename, cv2\u001B[38;5;241m.\u001B[39mIMREAD_COLOR)\n\u001B[0;32m      7\u001B[0m im \u001B[38;5;241m=\u001B[39m cv2\u001B[38;5;241m.\u001B[39mresize(im,(\u001B[38;5;241m0\u001B[39m,\u001B[38;5;241m0\u001B[39m),fx\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.5\u001B[39m,fy\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.5\u001B[39m)\n\u001B[1;32m----> 9\u001B[0m imMatches, imReg, h \u001B[38;5;241m=\u001B[39m \u001B[43malignImages_SIFT\u001B[49m\u001B[43m(\u001B[49m\u001B[43mim\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mimReference\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     10\u001B[0m \u001B[38;5;66;03m# Print estimated homography\u001B[39;00m\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEstimated homography : \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m, h)\n",
      "Cell \u001B[1;32mIn[3], line 11\u001B[0m, in \u001B[0;36malignImages_SIFT\u001B[1;34m(im1, im2)\u001B[0m\n\u001B[0;32m      9\u001B[0m \u001B[38;5;66;03m# Match features.\u001B[39;00m\n\u001B[0;32m     10\u001B[0m matcher \u001B[38;5;241m=\u001B[39m cv2\u001B[38;5;241m.\u001B[39mBFMatcher()\n\u001B[1;32m---> 11\u001B[0m matches \u001B[38;5;241m=\u001B[39m \u001B[43mmatcher\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmatch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdescriptors1\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdescriptors2\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mk\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     13\u001B[0m good \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m     14\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m m,n \u001B[38;5;129;01min\u001B[39;00m matches:\n",
      "\u001B[1;31merror\u001B[0m: OpenCV(4.9.0) :-1: error: (-5:Bad argument) in function 'match'\n> Overload resolution failed:\n>  - 'k' is an invalid keyword argument for DescriptorMatcher.match()\n>  - 'k' is an invalid keyword argument for DescriptorMatcher.match()\n>  - DescriptorMatcher.match() takes at most 2 arguments (3 given)\n>  - DescriptorMatcher.match() takes at most 2 arguments (3 given)\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "111f4368-6247-4af6-b743-d90f8c48a923",
   "metadata": {},
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(10, 20))\n",
    "fig2, axes2 = plt.subplots(1, 1, figsize=(10, 20))\n",
    "fig3, axes3 = plt.subplots(1, 1, figsize=(10, 10))\n",
    "\n",
    "for i in range(2):\n",
    "        axes[i].axis('off')\n",
    "axes2.axis('off')\n",
    "axes3.axis('off')\n",
    "\n",
    "axes[0].imshow(imReference[:,:,::-1])\n",
    "axes[0].set_title('Reference', fontsize=20)\n",
    "\n",
    "axes[1].imshow(im[:,:,::-1])\n",
    "axes[1].set_title('Original Img', fontsize=20)\n",
    "\n",
    "axes2.imshow(imMatches[:,:,::-1])\n",
    "axes2.set_title('Top matches', fontsize=20)\n",
    "\n",
    "axes3.imshow(imReg[:,:,::-1])\n",
    "axes3.set_title('Aligned Img', fontsize=20)\n",
    "\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "412523a3-3cf7-4b94-84ef-7d1513d17175",
   "metadata": {},
   "source": [
    "##### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
